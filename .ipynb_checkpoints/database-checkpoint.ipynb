{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sqlite3\n",
    "\n",
    "\n",
    "Scripts to run database migration, table creation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dbopen(object):\n",
    "    def __init__(self, path='data.db'):\n",
    "        self.path = path\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.conn = sqlite3.connect(self.path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        return self.cursor\n",
    "    \n",
    "    def __exit__(self, exc_class, exc, traceback):\n",
    "        self.conn.commit()\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_table():\n",
    "    with dbopen() as c:\n",
    "        c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS skill (\n",
    "            id integer PRIMARY KEY AUTOINCREMENT,\n",
    "            url text UNIQUE NOT NULL,\n",
    "            text text NOT NULL,\n",
    "            data json NOT NULL,\n",
    "            created_at timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
    "            updated_at timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP\n",
    "        )\"\"\")\n",
    "\n",
    "        c.execute(\"\"\"\n",
    "        CREATE TRIGGER IF NOT EXISTS update_timestamp\n",
    "        AFTER UPDATE ON skill \n",
    "        BEGIN\n",
    "            update skill set updated_at = current_timestamp WHERE url = NEW.url;\n",
    "        END\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 'https://appinventiv.com/blog/go-vs-rust/'), (3, 'https://buttercms.com/blog/vue-vs-react-which-is-the-better-framework'), (8, 'https://hackr.io/blog/kotlin-vs-java'), (4, 'https://www.edureka.co/blog/what-is-scala/'), (1, 'https://www.fullstackacademy.com/blog/nine-best-programming-languages-to-learn'), (2, 'https://www.ignite.digital/10-best-programming-languages-to-learn-in-2020/'), (6, 'https://www.sam-solutions.com/blog/top-10-programming-languages-and-their-use-cases/')]\n"
     ]
    }
   ],
   "source": [
    "with dbopen('data.db') as c:\n",
    "    result = c.execute('select id, url from skill').fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data\n",
    "\n",
    "In order to train the data for Spacy's NER, we first need to convert the format to the training data's format. We will load the data that is already stored in the database and change it to the following format:\n",
    "\n",
    "```python\n",
    "train_data = [\n",
    "    ('React, Vue is good', {\"entities\": [(0, 5, 'SKILL'), (7, 10, 'SKILL')]})\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "References:\n",
    "- https://spacy.io/usage/training\n",
    "- https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with dbopen() as c:\n",
    "    result = c.execute('select id, data from skill').fetchall()\n",
    "    for id, data in result:\n",
    "        json_data = json.loads(data)\n",
    "        for row in json_data:\n",
    "            txt, annotations = row['text'], row['annotations']\n",
    "            \n",
    "            annotation_format = [(annotation['start'], \n",
    "                                  annotation['end'], \n",
    "                                  annotation['label']) for annotation in annotations]\n",
    "            item_format = (txt, {\"entities\": annotation_format})\n",
    "            train_data.append(item_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Named Entity Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load pre-existing spacy model.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Getting the pipeline component.\n",
    "ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels to the `ner`.\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apart from `ner`, the model has other pipeline components. \n",
    "# These components should not get affected in training.\n",
    "# Disable the other pipeline components that you do not want to change.\n",
    "# Training will be performed with the unaffected_pipes disabled\n",
    "\n",
    "pipe_exceptions = ['ner', 'trf_wordpiecer', 'trf_tok2vec']\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "unaffected_pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Vue Router <template> <div id=\"app\"> <nav> <router...\" with entities \"[(0, 3, 'SKILL'), (205, 208, 'SKILL'), (215, 218, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"If you want to use the mutable Set , you’ll have t...\" with entities \"[(86, 91, 'SKILL')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"There are more than 66,000 questions on StackOverf...\" with entities \"[(61, 64, 'SKILL')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Source: GoogleTrends: Feb 2018 - Feb 2019 Evan You...\" with entities \"[(56, 59, 'SKILL')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"It has lots of automation tools for testing and de...\" with entities \"[(220, 223, 'SKILL'), (287, 289, 'SKILL'), (333, 3...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Yet Vue is more structured, easier to figure out a...\" with entities \"[(4, 7, 'SKILL'), (130, 133, 'SKILL')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"A recent search on StackOverflow shows that a Reac...\" with entities \"[(46, 51, 'SKILL'), (98, 101, 'SKILL')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Here is a quick summary of the different possibili...\" with entities \"[(140, 150, 'SKILL'), (152, 156, 'SKILL'), (158, 1...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"val a = Array(1,5,3,2,4)\n",
      "scala.util.Sorting.quickS...\" with entities \"[(25, 30, 'SKILL'), (151, 156, 'SKILL')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/alextanhongpin/.local/share/virtualenvs/natural_language_processing_with_python_co-tJ8vfo8Q/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Best programming languages: C/C++C/C++ are the bac...\" with entities \"[(30, 33, 'SKILL'), (35, 38, 'SKILL')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Losses: {'ner': 13531.097412541509}\n",
      "Iteration: 1 Losses: {'ner': 12047.109838575125}\n",
      "Iteration: 2 Losses: {'ner': 11484.289995610714}\n",
      "Iteration: 3 Losses: {'ner': 11353.18250232935}\n",
      "Iteration: 4 Losses: {'ner': 11238.585773326457}\n",
      "Iteration: 5 Losses: {'ner': 10996.600533246994}\n",
      "Iteration: 6 Losses: {'ner': 10827.820795580745}\n",
      "Iteration: 7 Losses: {'ner': 10880.216635167599}\n",
      "Iteration: 8 Losses: {'ner': 10854.939557492733}\n",
      "Iteration: 9 Losses: {'ner': 10873.098056912422}\n",
      "Iteration: 10 Losses: {'ner': 10603.298558929004}\n",
      "Iteration: 11 Losses: {'ner': 10716.066584825516}\n",
      "Iteration: 12 Losses: {'ner': 10665.229402981699}\n",
      "Iteration: 13 Losses: {'ner': 10666.979851424694}\n",
      "Iteration: 14 Losses: {'ner': 10586.12006700039}\n",
      "Iteration: 15 Losses: {'ner': 10492.14964979887}\n",
      "Iteration: 16 Losses: {'ner': 10504.174914717674}\n",
      "Iteration: 17 Losses: {'ner': 10495.253044366837}\n",
      "Iteration: 18 Losses: {'ner': 10407.500497195462}\n",
      "Iteration: 19 Losses: {'ner': 10522.784501433372}\n",
      "Iteration: 20 Losses: {'ner': 10556.531236380339}\n",
      "Iteration: 21 Losses: {'ner': 10438.903997600079}\n",
      "Iteration: 22 Losses: {'ner': 10544.887460008264}\n",
      "Iteration: 23 Losses: {'ner': 10494.003029108047}\n",
      "Iteration: 24 Losses: {'ner': 10525.71180479275}\n",
      "Iteration: 25 Losses: {'ner': 10533.82414123416}\n",
      "Iteration: 26 Losses: {'ner': 10605.424723565578}\n",
      "Iteration: 27 Losses: {'ner': 10451.414473325014}\n",
      "Iteration: 28 Losses: {'ner': 10401.735592767596}\n",
      "Iteration: 29 Losses: {'ner': 10414.52792493999}\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Training the model.\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "    \n",
    "\n",
    "    for iteration in range(30): # 1\n",
    "        random.shuffle(train_data) # 2\n",
    "        losses = {}\n",
    "        \n",
    "        batches = minibatch(train_data, \n",
    "                            size=compounding(4.0, 32.0, 1.001)) # 3\n",
    "            \n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts,\n",
    "                       annotations,\n",
    "                       drop=0.5, # Make it harder to memorize data.\n",
    "                       losses=losses)\n",
    "        print('Iteration:', iteration, 'Losses:', losses)\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. To train the `ner` model, the model has to be looped over the example for sufficient number of iterations. If you train it for like just 5-6 iterations, it may not be effective. NOTE: find out what is the most effective number.\n",
    "2. Before every iteration it's a good practice to shuffle the examples randomly through random.shuffle() function. \n",
    "This ensures that the model does not make generalization based on the order of the examples.\n",
    "3. Training data is passed in batch. We use `minibatch()` function over the training data that will return data in batches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Scala', 'SKILL'), ('go', 'SKILL')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('I want to learn Scala, go is also good.')\n",
    "print('Entities', [(ent.text, ent.label_) \n",
    "                  for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('can I learn js? Using a single threaded language like node.js is good for IO')\n",
    "print('Entities', [(ent.text, ent.label_) \n",
    "                  for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020_08_07'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.now().strftime('%Y_%m_%d')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to content/2020_08_07\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "target_dir = f'content/{today}/'\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "output_dir = Path(target_dir)\n",
    "nlp.to_disk(output_dir)\n",
    "print('Saved model to', output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from content/2020_08_07/\n"
     ]
    }
   ],
   "source": [
    "print('Loading from', target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Kotlin', 'SKILL')]\n",
      "Entities []\n",
      "Entities [('react', 'SKILL')]\n",
      "Entities [('Python', 'SKILL'), ('Go', 'SKILL'), ('JavaScript', 'SKILL'), ('Rust', 'SKILL')]\n",
      "Entities [('Swift', 'SKILL')]\n"
     ]
    }
   ],
   "source": [
    "nlp_updated = spacy.load(output_dir)\n",
    "\n",
    "test_data = ['Kotlin is an awesome programming language', \n",
    "             'Should I learn ReactJS in 2020?',\n",
    "             'Should I learn react in 2020?',\n",
    "             'Peter is learning Python, Go, JavaScript and Rust',\n",
    "             'Apple uses Swift programming language for iOS']\n",
    "for data in test_data:\n",
    "    doc = nlp_updated(data)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
