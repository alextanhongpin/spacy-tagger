{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sqlite3\n",
    "\n",
    "\n",
    "Scripts to run database migration, table creation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dbopen(object):\n",
    "    def __init__(self, path='data.db'):\n",
    "        self.path = path\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.conn = sqlite3.connect(self.path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        return self.cursor\n",
    "    \n",
    "    def __exit__(self, exc_class, exc, traceback):\n",
    "        self.conn.commit()\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table():\n",
    "    with dbopen() as c:\n",
    "        c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS skill (\n",
    "            id integer PRIMARY KEY AUTOINCREMENT,\n",
    "            url text UNIQUE NOT NULL,\n",
    "            text text NOT NULL,\n",
    "            data json NOT NULL,\n",
    "            created_at timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
    "            updated_at timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP\n",
    "        )\"\"\")\n",
    "\n",
    "        c.execute(\"\"\"\n",
    "        CREATE TRIGGER IF NOT EXISTS update_timestamp\n",
    "        AFTER UPDATE ON skill \n",
    "        BEGIN\n",
    "            update skill set updated_at = current_timestamp WHERE url = NEW.url;\n",
    "        END\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'https://buttercms.com/blog/vue-vs-react-which-is-the-better-framework'), (1, 'https://www.fullstackacademy.com/blog/nine-best-programming-languages-to-learn'), (2, 'https://www.ignite.digital/10-best-programming-languages-to-learn-in-2020/')]\n"
     ]
    }
   ],
   "source": [
    "with dbopen('data.db') as c:\n",
    "    result = c.execute('select id, url from skill').fetchall()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data\n",
    "\n",
    "In order to train the data for Spacy's NER, we first need to convert the format to the training data's format. We will load the data that is already stored in the database and change it to the following format:\n",
    "\n",
    "```python\n",
    "train_data = [\n",
    "    ('React, Vue is good', {\"entities\": [(0, 5, 'SKILL'), (7, 10, 'SKILL')]})\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "References:\n",
    "- https://spacy.io/usage/training\n",
    "- https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with dbopen() as c:\n",
    "    result = c.execute('select id, data from skill').fetchall()\n",
    "    for id, data in result:\n",
    "        json_data = json.loads(data)\n",
    "        for row in json_data:\n",
    "            txt, annotations = row['text'], row['annotations']\n",
    "            \n",
    "            annotation_format = [(annotation['start'], \n",
    "                                  annotation['end'], \n",
    "                                  annotation['label']) for annotation in annotations]\n",
    "            item_format = (txt, {\"entities\": annotation_format})\n",
    "            train_data.append(item_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Named Entity Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load pre-existing spacy model.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Getting the pipeline component.\n",
    "ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels to the `ner`.\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apart from `ner`, the model has other pipeline components. \n",
    "# These components should not get affected in training.\n",
    "# Disable the other pipeline components that you do not want to change.\n",
    "# Training will be performed with the unaffected_pipes disabled\n",
    "\n",
    "pipe_exceptions = ['ner', 'trf_wordpiecer', 'trf_tok2vec']\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "unaffected_pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: {'ner': 4313.194564044476}\n",
      "Losses: {'ner': 4319.868515312672}\n",
      "Losses: {'ner': 4250.519708633423}\n",
      "Losses: {'ner': 4297.394887566334}\n",
      "Losses: {'ner': 4266.092610955238}\n",
      "Losses: {'ner': 4257.727110803127}\n",
      "Losses: {'ner': 4242.515068352222}\n",
      "Losses: {'ner': 4259.796709120274}\n",
      "Losses: {'ner': 4232.821398139}\n",
      "Losses: {'ner': 4288.099318742752}\n",
      "Losses: {'ner': 4242.986487769755}\n",
      "Losses: {'ner': 4280.384516149759}\n",
      "Losses: {'ner': 4192.164559528232}\n",
      "Losses: {'ner': 4227.983571827412}\n",
      "Losses: {'ner': 4322.200461566448}\n",
      "Losses: {'ner': 4258.277119457722}\n",
      "Losses: {'ner': 4324.17472076416}\n",
      "Losses: {'ner': 4188.70452439785}\n",
      "Losses: {'ner': 4281.788178563118}\n",
      "Losses: {'ner': 4181.140057787299}\n",
      "Losses: {'ner': 4192.5527376532555}\n",
      "Losses: {'ner': 4245.895878076553}\n",
      "Losses: {'ner': 4241.292424976826}\n",
      "Losses: {'ner': 4230.300799235702}\n",
      "Losses: {'ner': 4249.96360481903}\n",
      "Losses: {'ner': 4227.023162007332}\n",
      "Losses: {'ner': 4224.95201574266}\n",
      "Losses: {'ner': 4202.549118487164}\n",
      "Losses: {'ner': 4229.395787477493}\n",
      "Losses: {'ner': 4216.8399411179125}\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Training the model.\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "    \n",
    "\n",
    "    for iteration in range(30): # 1\n",
    "        random.shuffle(train_data) # 2\n",
    "        losses = {}\n",
    "        \n",
    "        batches = minibatch(train_data, \n",
    "                            size=compounding(4.0, 32.0, 1.001)) # 3\n",
    "            \n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts,\n",
    "                       annotations,\n",
    "                       drop=0.5, # Make it harder to memorize data.\n",
    "                       losses=losses)\n",
    "        print('Iteration:', iteration, 'Losses:', losses)\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. To train the `ner` model, the model has to be looped over the example for sufficient number of iterations. If you train it for like just 5-6 iterations, it may not be effective. NOTE: find out what is the most effective number.\n",
    "2. Before every iteration it's a good practice to shuffle the examples randomly through random.shuffle() function. \n",
    "This ensures that the model does not make generalization based on the order of the examples.\n",
    "3. Training data is passed in batch. We use `minibatch()` function over the training data that will return data in batches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Scala', 'SKILL'), ('go', 'SKILL')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('I want to learn Scala, go is also good.')\n",
    "print('Entities', [(ent.text, ent.label_) \n",
    "                  for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('node.js', 'SKILL')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('can I learn js? Using a single threaded language like node.js is good for IO')\n",
    "print('Entities', [(ent.text, ent.label_) \n",
    "                  for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020_08_07'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.now().strftime('%Y_%m_%d')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to content/2020_08_07\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "target_dir = f'content/{today}/'\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "output_dir = Path(target_dir)\n",
    "nlp.to_disk(output_dir)\n",
    "print('Saved model to', output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from content/2020_08_07/\n"
     ]
    }
   ],
   "source": [
    "print('Loading from', target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Kotlin', 'SKILL')]\n",
      "Entities [('ReactJS', 'SKILL')]\n",
      "Entities [('Python', 'SKILL'), ('Go', 'SKILL'), ('JavaScript', 'SKILL'), ('Rust', 'SKILL')]\n",
      "Entities [('Swift', 'SKILL')]\n"
     ]
    }
   ],
   "source": [
    "nlp_updated = spacy.load(output_dir)\n",
    "\n",
    "test_data = ['Kotlin is an awesome programming language', \n",
    "             'Should I learn ReactJS in 2020?',\n",
    "             'Peter is learning Python, Go, JavaScript and Rust',\n",
    "             'Apple uses Swift programming language for iOS']\n",
    "for data in test_data:\n",
    "    doc = nlp_updated(data)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
